{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7745cc0b-98ca-40e2-8fa9-956c0c9813d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1547d727-9455-4418-a310-3abe44c20802",
   "metadata": {},
   "outputs": [],
   "source": [
    "para =\"\"\"During my academic journey, I developed a strong interest in Natural Language Processing (NLP), a domain that combines the power of linguistics and machine learning. To build a strong foundation, I extensively worked with the NLTK (Natural Language Toolkit), an essential Python library for text processing and computational linguistics. Using NLTK, I gained hands-on experience with tasks such as tokenization, stemming, lemmatization, POS tagging, and sentiment analysis. I implemented various NLP pipelines for analyzing textual data and built small projects such as chatbot frameworks and automated text summarizers. This practical exposure helped me understand the complexity of human language and the challenges in machine understanding. I am now eager to take this knowledge forward in an advanced research environment like TUM, where I can deepen my expertise and contribute to innovative NLP applications with real-world impact.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "667a81e3-d3f7-4d1a-9c1a-a78e542a2342",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = nltk.sent_tokenize(para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58952979-2ead-4d0f-9c78-94586310994b",
   "metadata": {},
   "outputs": [],
   "source": [
    "word = nltk.word_tokenize(para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72fd24c7-a169-4060-a290-e61853d6644b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['During',\n",
       " 'my',\n",
       " 'academic',\n",
       " 'journey',\n",
       " ',',\n",
       " 'I',\n",
       " 'developed',\n",
       " 'a',\n",
       " 'strong',\n",
       " 'interest',\n",
       " 'in',\n",
       " 'Natural',\n",
       " 'Language',\n",
       " 'Processing',\n",
       " '(',\n",
       " 'NLP',\n",
       " ')',\n",
       " ',',\n",
       " 'a',\n",
       " 'domain',\n",
       " 'that',\n",
       " 'combines',\n",
       " 'the',\n",
       " 'power',\n",
       " 'of',\n",
       " 'linguistics',\n",
       " 'and',\n",
       " 'machine',\n",
       " 'learning',\n",
       " '.',\n",
       " 'To',\n",
       " 'build',\n",
       " 'a',\n",
       " 'strong',\n",
       " 'foundation',\n",
       " ',',\n",
       " 'I',\n",
       " 'extensively',\n",
       " 'worked',\n",
       " 'with',\n",
       " 'the',\n",
       " 'NLTK',\n",
       " '(',\n",
       " 'Natural',\n",
       " 'Language',\n",
       " 'Toolkit',\n",
       " ')',\n",
       " ',',\n",
       " 'an',\n",
       " 'essential',\n",
       " 'Python',\n",
       " 'library',\n",
       " 'for',\n",
       " 'text',\n",
       " 'processing',\n",
       " 'and',\n",
       " 'computational',\n",
       " 'linguistics',\n",
       " '.',\n",
       " 'Using',\n",
       " 'NLTK',\n",
       " ',',\n",
       " 'I',\n",
       " 'gained',\n",
       " 'hands-on',\n",
       " 'experience',\n",
       " 'with',\n",
       " 'tasks',\n",
       " 'such',\n",
       " 'as',\n",
       " 'tokenization',\n",
       " ',',\n",
       " 'stemming',\n",
       " ',',\n",
       " 'lemmatization',\n",
       " ',',\n",
       " 'POS',\n",
       " 'tagging',\n",
       " ',',\n",
       " 'and',\n",
       " 'sentiment',\n",
       " 'analysis',\n",
       " '.',\n",
       " 'I',\n",
       " 'implemented',\n",
       " 'various',\n",
       " 'NLP',\n",
       " 'pipelines',\n",
       " 'for',\n",
       " 'analyzing',\n",
       " 'textual',\n",
       " 'data',\n",
       " 'and',\n",
       " 'built',\n",
       " 'small',\n",
       " 'projects',\n",
       " 'such',\n",
       " 'as',\n",
       " 'chatbot',\n",
       " 'frameworks',\n",
       " 'and',\n",
       " 'automated',\n",
       " 'text',\n",
       " 'summarizers',\n",
       " '.',\n",
       " 'This',\n",
       " 'practical',\n",
       " 'exposure',\n",
       " 'helped',\n",
       " 'me',\n",
       " 'understand',\n",
       " 'the',\n",
       " 'complexity',\n",
       " 'of',\n",
       " 'human',\n",
       " 'language',\n",
       " 'and',\n",
       " 'the',\n",
       " 'challenges',\n",
       " 'in',\n",
       " 'machine',\n",
       " 'understanding',\n",
       " '.',\n",
       " 'I',\n",
       " 'am',\n",
       " 'now',\n",
       " 'eager',\n",
       " 'to',\n",
       " 'take',\n",
       " 'this',\n",
       " 'knowledge',\n",
       " 'forward',\n",
       " 'in',\n",
       " 'an',\n",
       " 'advanced',\n",
       " 'research',\n",
       " 'environment',\n",
       " 'like',\n",
       " 'TUM',\n",
       " ',',\n",
       " 'where',\n",
       " 'I',\n",
       " 'can',\n",
       " 'deepen',\n",
       " 'my',\n",
       " 'expertise',\n",
       " 'and',\n",
       " 'contribute',\n",
       " 'to',\n",
       " 'innovative',\n",
       " 'NLP',\n",
       " 'applications',\n",
       " 'with',\n",
       " 'real-world',\n",
       " 'impact',\n",
       " '.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34af7316-337e-49fb-a8be-23252fb483bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['During my academic journey, I developed a strong interest in Natural Language Processing (NLP), a domain that combines the power of linguistics and machine learning.',\n",
       " 'To build a strong foundation, I extensively worked with the NLTK (Natural Language Toolkit), an essential Python library for text processing and computational linguistics.',\n",
       " 'Using NLTK, I gained hands-on experience with tasks such as tokenization, stemming, lemmatization, POS tagging, and sentiment analysis.',\n",
       " 'I implemented various NLP pipelines for analyzing textual data and built small projects such as chatbot frameworks and automated text summarizers.',\n",
       " 'This practical exposure helped me understand the complexity of human language and the challenges in machine understanding.',\n",
       " 'I am now eager to take this knowledge forward in an advanced research environment like TUM, where I can deepen my expertise and contribute to innovative NLP applications with real-world impact.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6b9726a9-6295-488f-9a79-034e90fb90ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer  = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f8b12166-fc8e-49bd-8a6d-9b110fbee61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sent)):\n",
    "    words = nltk.word_tokenize(sent[i])\n",
    "    words = [stemmer.stem(word) for word in words if word not in set(stopwords.words('english'))]\n",
    "    sent[i] = ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2e000c49-8e3d-44b0-9469-1d51e9cf6c8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "13d25de9-daf1-43b7-8f22-eb93de85c0c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dure academ journey , i develop strong interest natur languag process ( nlp ) , domain combin power linguist machin learn .',\n",
       " 'to build strong foundat , i extens work nltk ( natur languag toolkit ) , essenti python librari text process comput linguist .',\n",
       " 'use nltk , i gain hands-on experi task token , stem , lemmat , po tag , sentiment analysi .',\n",
       " 'i implement variou nlp pipelin analyz textual data built small project chatbot framework autom text summar .',\n",
       " 'thi practic exposur help understand complex human languag challeng machin understand .',\n",
       " 'i eager take knowledg forward advanc research environ like tum , i deepen expertis contribut innov nlp applic real-world impact .']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426c6ca1-5b0a-47e4-8a90-1710a3b05522",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
